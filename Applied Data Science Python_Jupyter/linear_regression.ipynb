{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time_series import load_data, split_trips # this is available from one of my other python notebooks\n",
    "vdf, _ = load_data('bus_train.db')\n",
    "all_trips = split_trips(vdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 506, 21: 200, 18: 190, 20: 184, 19: 163, 16: 162, 22: 159, 17: 151, 23: 139, 31: 132, 15: 128, 2: 125, 34: 112, 32: 111, 33: 101, 28: 98, 14: 97, 35: 95, 30: 95, 29: 93, 24: 90, 25: 89, 37: 86, 39: 83, 27: 83, 38: 82, 36: 77, 26: 75, 40: 70, 13: 62, 41: 53, 44: 52, 42: 47, 6: 44, 12: 39, 46: 39, 5: 39, 7: 38, 3: 36, 47: 33, 45: 33, 43: 31, 48: 27, 49: 26, 4: 26, 11: 25, 50: 25, 10: 23, 51: 23, 8: 19, 9: 18, 53: 16, 54: 15, 52: 14, 55: 14, 56: 8, 58: 3, 59: 3, 57: 3, 60: 3, 61: 1, 67: 1, 62: 1})\n",
      "               tmstmp   vid        lat        lon  hdg   pid   rt        des  \\\n",
      "0 2016-08-11 10:56:00  5549  40.439504 -79.996981  114  4521  61A  Swissvale   \n",
      "1 2016-08-11 10:57:00  5549  40.439504 -79.996981  114  4521  61A  Swissvale   \n",
      "2 2016-08-11 10:58:00  5549  40.438842 -79.994733  124  4521  61A  Swissvale   \n",
      "3 2016-08-11 10:59:00  5549  40.437938 -79.991213   94  4521  61A  Swissvale   \n",
      "4 2016-08-11 10:59:00  5549  40.437938 -79.991213   94  4521  61A  Swissvale   \n",
      "\n",
      "   pdist  spd tablockid  tatripid   eta  \n",
      "0   1106    0  061A-164      6691  16.0  \n",
      "1   1106    0  061A-164      6691  15.0  \n",
      "2   1778    8  061A-164      6691  14.0  \n",
      "3   2934    7  061A-164      6691  13.0  \n",
      "4   2934    7  061A-164      6691  13.0  \n"
     ]
    }
   ],
   "source": [
    "def label_and_truncate(trip, bus_stop_coordinates):\n",
    "    \"\"\" Given a dataframe of a trip following the specification in the previous homework assignment,\n",
    "        generate the labels and throw away irrelevant rows. \n",
    "        \n",
    "        Args: \n",
    "            trip (dataframe): a dataframe from the list outputted by split_trips from homework 2\n",
    "            stop_coordinates ((float, float)): a pair of floats indicating the (latitude, longitude) \n",
    "                                               coordinates of the target bus stop. \n",
    "            \n",
    "        Return:\n",
    "            (dataframe): a labeled trip that is truncated at Forbes and Morewood and contains a new column \n",
    "                         called `eta` which contains the number of minutes until it reaches the bus stop. \n",
    "        \"\"\"\n",
    "    \n",
    "    idx_array = pd.DataFrame()\n",
    "    idx_array['dist'] = ((trip.lat - bus_stop_coordinates[0])**2 + (trip.lon - bus_stop_coordinates[1])**2)\n",
    "    idx_array['idx'] = range(len(idx_array))\n",
    "    \n",
    "    min_value = idx_array['dist'].idxmin()\n",
    "    idx_array.set_index(idx_array.idx, inplace = True)\n",
    "    min_d = idx_array[idx_array['dist']==idx_array['dist'].min()].index.values\n",
    "    \n",
    "    eta_ = (min_value - trip.index).total_seconds() / 60.0\n",
    "    trip['eta'] = eta_\n",
    "    return trip.head(min_d[0]+1)\n",
    "\n",
    "    \n",
    "morewood_coordinates = (40.444671114203, -79.94356058465502) # (lat, lon)\n",
    "labeled_trips = [label_and_truncate(trip, morewood_coordinates) for trip in all_trips]\n",
    "labeled_vdf = pd.concat(labeled_trips).reset_index()\n",
    "labeled_vdf = labeled_vdf[labeled_vdf[\"eta\"] < 10*60].reset_index(drop=True)\n",
    "print(Counter([len(t) for t in labeled_trips]))\n",
    "print(labeled_vdf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Basic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def create_features(vdf):\n",
    "    \"\"\" Given a dataframe of labeled and truncated bus data, generate features for linear regression. \n",
    "    \n",
    "        Args:\n",
    "            df (dataframe) : dataframe of bus data with the eta column and truncated rows\n",
    "        Return: \n",
    "            (dataframe) : dataframe of features for each example\n",
    "        \"\"\"\n",
    "    vdf.reset_index()\n",
    "    vdf[\"bias\"] = 1\n",
    "    vdf[\"day\"] = vdf.tmstmp.dt.weekday\n",
    "    vdf[\"hour\"] = vdf.tmstmp.dt.hour\n",
    "    vdf[\"min\"] = (vdf.tmstmp.dt.hour * 60) + vdf.tmstmp.dt.minute\n",
    "    \n",
    "    vdf[\"sin_day_of_week\"] = vdf[\"day\"].apply(lambda x: math.sin((2*math.pi)*(x/7)))\n",
    "    vdf[\"cos_day_of_week\"] = vdf[\"day\"].apply(lambda x: math.cos((2*math.pi)*(x/7)))\n",
    "    vdf[\"sin_hour_of_day\"] = vdf[\"hour\"].apply(lambda x: math.sin((2*math.pi)*(x/24)))\n",
    "    vdf[\"cos_hour_of_day\"] = vdf[\"hour\"].apply(lambda x: math.cos((2*math.pi)*(x/24)))\n",
    "    vdf[\"sin_time_of_day\"] = vdf[\"min\"].apply(lambda x: math.sin((2*math.pi)*(x/1440)))\n",
    "    vdf[\"cos_time_of_day\"] = vdf[\"min\"].apply(lambda x: math.cos((2*math.pi)*(x/1440)))\n",
    "    vdf[\"sin_hdg\"] = vdf[\"hdg\"].apply(lambda x: math.sin((2*math.pi)*(x/360)))\n",
    "    vdf[\"cos_hdg\"] = vdf[\"hdg\"].apply(lambda x: math.cos((2*math.pi)*(x/360)))\n",
    "    \n",
    "    vdf['weekday'] = np.where(vdf.day<=4, 1,0)\n",
    "    \n",
    "    rt = pd.get_dummies(vdf['rt'])\n",
    "    dest = pd.get_dummies(vdf['des'])\n",
    "    vdf = pd.merge(vdf, dest, left_index=True, right_index=True)\n",
    "    vdf = pd.merge(vdf, rt, left_index=True, right_index=True)\n",
    "    \n",
    "    vdf.drop(['tmstmp','vid','pid','hdg','tablockid','tatripid','rt', 'des','day','hour','min'], axis = 1, inplace = True)\n",
    "    \n",
    "    return vdf\n",
    "\n",
    "vdf_features = create_features(labeled_vdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lat', 'lon', 'pdist', 'spd', 'eta', 'bias', 'sin_hdg', 'cos_hdg',\n",
      "       'sin_day_of_week', 'cos_day_of_week', 'sin_hour_of_day',\n",
      "       'cos_hour_of_day', 'sin_time_of_day', 'cos_time_of_day', 'weekday',\n",
      "       'Braddock ', 'Downtown', 'Greenfield Only', 'McKeesport ',\n",
      "       'Murray-Waterfront', 'Swissvale', '61A', '61B', '61C', '61D'],\n",
      "      dtype='object')\n",
      "         lat        lon  pdist  spd   eta  bias   sin_hdg   cos_hdg  \\\n",
      "0  40.439504 -79.996981   1106    0  16.0     1  0.913545 -0.406737   \n",
      "1  40.439504 -79.996981   1106    0  15.0     1  0.913545 -0.406737   \n",
      "2  40.438842 -79.994733   1778    8  14.0     1  0.829038 -0.559193   \n",
      "3  40.437938 -79.991213   2934    7  13.0     1  0.997564 -0.069756   \n",
      "4  40.437938 -79.991213   2934    7  13.0     1  0.997564 -0.069756   \n",
      "\n",
      "   sin_day_of_week  cos_day_of_week  sin_hour_of_day  cos_hour_of_day  \\\n",
      "0         0.433884        -0.900969              0.5        -0.866025   \n",
      "1         0.433884        -0.900969              0.5        -0.866025   \n",
      "2         0.433884        -0.900969              0.5        -0.866025   \n",
      "3         0.433884        -0.900969              0.5        -0.866025   \n",
      "4         0.433884        -0.900969              0.5        -0.866025   \n",
      "\n",
      "   sin_time_of_day  cos_time_of_day  weekday  Braddock   Downtown  \\\n",
      "0         0.275637        -0.961262        1          0         0   \n",
      "1         0.271440        -0.962455        1          0         0   \n",
      "2         0.267238        -0.963630        1          0         0   \n",
      "3         0.263031        -0.964787        1          0         0   \n",
      "4         0.263031        -0.964787        1          0         0   \n",
      "\n",
      "   Greenfield Only  McKeesport   Murray-Waterfront  Swissvale  61A  61B  61C  \\\n",
      "0                0            0                  0          1    1    0    0   \n",
      "1                0            0                  0          1    1    0    0   \n",
      "2                0            0                  0          1    1    0    0   \n",
      "3                0            0                  0          1    1    0    0   \n",
      "4                0            0                  0          1    1    0    0   \n",
      "\n",
      "   61D  \n",
      "0    0  \n",
      "1    0  \n",
      "2    0  \n",
      "3    0  \n",
      "4    0  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', 26):\n",
    "    print(vdf_features.columns)\n",
    "    print(vdf_features.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear Regression using Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_model():\n",
    "    \"\"\" Perform linear regression and predict the output on unseen examples. \n",
    "        Attributes: \n",
    "            beta (array_like) : vector containing parameters for the features \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        \"\"\" Initialize the linear regression model by computing the estimate of the weights parameter\n",
    "            Args: \n",
    "                X (array-like) : feature matrix of training data where each row corresponds to an example\n",
    "                y (array like) : vector of training data outputs \n",
    "            \"\"\"\n",
    "        lambda_ = math.pow(10,-4)\n",
    "        X_T_X = X.T.dot(X)\n",
    "        stabilizer = np.identity(X.shape[1]) * lambda_\n",
    "        invert_X_T_X = X_T_X + stabilizer\n",
    "        cholesky_fact = la.cho_factor(invert_X_T_X)\n",
    "        X_T_Y = X.T.dot(y)\n",
    "        self.beta = la.cho_solve(cholesky_fact, X_T_Y)\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X_p): \n",
    "        \"\"\" Predict the output of X_p using this linear model. \n",
    "            Args: \n",
    "                X_p (array_like) feature matrix of predictive data where each row corresponds to an example\n",
    "            Return: \n",
    "                (array_like) vector of predicted outputs for the X_p\n",
    "            \"\"\"\n",
    "        return np.array(X_p.values.dot(self.beta)).flatten()\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean squared error on both the training and validation set\n",
    "def compute_mse(LR, X, y, X_v, y_v):\n",
    "    \"\"\" Given a linear regression model, calculate the mean squared error for the \n",
    "        training dataset, the validation dataset, and for a mean prediction\n",
    "        Args:\n",
    "            LR (LR_model) : Linear model\n",
    "            X (array-like) : feature matrix of training data where each row corresponds to an example\n",
    "            y (array like) : vector of training data outputs \n",
    "            X_v (array-like) : feature matrix of validation data where each row corresponds to an example\n",
    "            y_v (array like) : vector of validation data outputs \n",
    "        Return: \n",
    "            (train_mse, train_mean_mse, \n",
    "             valid_mse, valid_mean_mse) : a 4-tuple of mean squared errors\n",
    "                                             1. MSE of linear regression on the training set\n",
    "                                             2. MSE of predicting the mean on the training set\n",
    "                                             3. MSE of linear regression on the validation set\n",
    "                                             4. MSE of predicting the mean on the validation set\n",
    "                         \n",
    "            \n",
    "    \"\"\"\n",
    "    y_pred = LR.predict(X)\n",
    "    y_v_pred = LR.predict(X_v)\n",
    "    \n",
    "    y_mean = LR.predict(X).mean()\n",
    "    mse_ltrain = ((y_pred - y) ** 2).mean(axis=None)\n",
    "    mse_lvalid = ((y_v_pred - y_v) ** 2).mean(axis=None)\n",
    "    mse_ptrain = ((y - y_mean) ** 2).mean(axis=None)\n",
    "    mse_pvalid = ((y_v - y_mean) ** 2).mean(axis=None)\n",
    "    \n",
    "    return(mse_ltrain, mse_ptrain, mse_lvalid, mse_pvalid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrueTime Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_truetime(LR, labeled_vdf, pdf):\n",
    "    \"\"\" Compute the mse of the truetime predictions and the linear regression mse on entries that have predictions.\n",
    "        Args:\n",
    "            LR (LR_model) : an already trained linear model\n",
    "            labeled_vdf (pd.DataFrame): a dataframe of the truncated and labeled bus data (same as the input to create_features)\n",
    "            pdf (pd.DataFrame): a dataframe of TrueTime predictions\n",
    "        Return: \n",
    "            (tt_mse, lr_mse): a tuple of the TrueTime MSE, and the linear regression MSE\n",
    "        \"\"\"\n",
    "    \n",
    "    columns = list(labeled_vdf)\n",
    "    pdf_filtered = pdf[pdf['prdtm']!='']\n",
    "    \n",
    "    m_vdf = labeled_vdf.merge(pdf_filtered, how='inner')\n",
    "    vdf_features = create_features(m_vdf.filter(columns, axis=1))\n",
    "    \n",
    "    X_df = vdf_features.loc[:, vdf_features.columns != 'eta']\n",
    "    y_pred = LR.predict(X_df)\n",
    "    \n",
    "    m_vdf['eta_prediction'] = y_pred\n",
    "    m_vdf['eta_'] = (m_vdf['prdtm'] - m_vdf['tmstmp']).apply(lambda x: x  / np.timedelta64(1,'m')).astype('int64')\n",
    "\n",
    "    mse_o = ((m_vdf['eta_'] - m_vdf['eta']) ** 2).mean(axis=None)\n",
    "    mse_p = ((m_vdf['eta_prediction'] - m_vdf['eta']) ** 2).mean(axis=None)\n",
    "    return(mse_o, mse_p)\n",
    "    \n",
    "    \n",
    "compare_truetime(LR, labeled_vdf_valid, pdf_valid)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
